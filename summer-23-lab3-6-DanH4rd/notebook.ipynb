{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d272112-d786-4e22-9dc0-6057d9f461e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Raport"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772bce02-b87a-495a-ba09-bb5daa4d690a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Krótkie odpowiedzi na pytania\n",
    "\n",
    "* Ile znajduje się w zbiorze cech kategorycznych, a ile numerycznych\n",
    "\n",
    "Mamy 5 wartości numerycznych, pozostałe są nominalne\n",
    "\n",
    "* Czy zmienna wyjściowa jest kategoryczna, czy numeryczna\n",
    "\n",
    "Jest numeryczną\n",
    "\n",
    "* Czy i ile w zbiorze jest brakujących wartości? Dla jakich zmiennych? Co z tego wynika?\n",
    "\n",
    "Dla wartości niezbędnych do analizy wydźwięku procent brakujących wartości wynosi mniej niż 1 procent\n",
    "\n",
    "* Czy któreś z cech są skorelowane? Co z tego może wynikać?\n",
    "\n",
    "Ogólnie nie mamy silnych korelacji\n",
    "\n",
    "* Czy któraś z cech koreluje ze zmienną wyjściową? Jeśli tak - która? Czy któraś nie koreluje?\n",
    "'overall' ma relatywnie wysoką korelacje dla czasu i kategorji, ale nie ma dostatecznie silnych korelacji\n",
    "\n",
    "* Czy zbiór danych wydaje się być wystarczająco informacyjny by rozwiązać zadanie analizy sentymentu?\n",
    "\n",
    "Tak\n",
    "\n",
    "* Czy któreś ze słów wydają się dominować w zbiorze?\n",
    "W tekście dominują słowa \"pomocnicze\" jak \"the\", \"in\", \"for\" etc. Po usunęciu \"common language\" dominują słowy opisujący towar (co to jest, czy pracuje)\n",
    "\n",
    "* Czy najpopularniejsze słowa różnią się znacząco pomiędzy klasami? Czy potrafisz wyróżnić słowa mogące wpływać w znaczym stopniu na sentyment?\n",
    "\n",
    "Możemy rozróżnić słowy pomiędzy klasami z uwagą, że różnice są mniej widoczne porównując 1 z 2 i 3 z 4\n",
    "\n",
    "* Jaka jest charakterystyka tekstu \n",
    "\n",
    "Najwięcej tekstów o krótkiej długości (do ok. 5 tyś symboli dla 'reviewText' i 60 symboli do 'summary')\n",
    "\n",
    "# Ogólne wnioski\n",
    "\n",
    "Dane mają dużo atrybutów, ale do budowania modelu przydatna jest tylko część. Niezbędnymi są atrybuty tekstowe 'summary' i 'reviewText' i atrybut klasy 'overall'.\n",
    "\n",
    "Do budowaniu modelu mogą też pszydać 'category' i 'unixReviewTime' (lub inna wartość czasu), które nie mają brakujące wartości, jednak to zależy od celu modelu, czy chcemy ogólnie analizować tekst na sentyment lub chcemy model analizy sentymentów dla review na Amazon dla wybranych kategorii i/lub czasu (bo dla różnych kategorii i czasu mogą być inne kryterium dla dobrego lub złego produktu).\n",
    "\n",
    "Nie mamy silnych korelacji pomiędzy atrybutami numerycznymi. Ale nie jest to problemem bo bardziej nam potrzebne wartości nominalne i nie stoi nam problem redukcji wymiarowości.\n",
    "\n",
    "Jedną z największych problemów który ma ten dataset to nierównomierny rozkład wartości klas. Klas o wartości '1' (najlepszy sentyment) jest więcej niż wszystkich pozostałych. Może to spowodować problemy z uczeniem i ewaluacją modelu, bo model może się nauczyć wykrywać tylko klasę '1'.\n",
    "\n",
    "Następnym problemem jest jakie słowa używać, bo najwięcej występują słowy zawierające niewiele informacji jak \"the\", \"for\", \"i\" itd. Możemy przy pomocy bibliotek usunąć takie słowy, ale wtedy tracimy takie słowy jak \"not\" i \"but\", które zawirają potzebną nam informacje. Ale nawet po usunięciu \"common language\" mamy zbędne słowy jako typ produktu lub jakieś przedmioty. Dlatego pytaniem jest jak wybrać potrzebne lub jak usunąć niepotrzebne słowy dla budowania modelu, czy wybrać pewne słowy które będą używane do analizy lub dopasować listę zbędnych słów aby nie usuwały się nam słowy niezbędne.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1295c20d-73cb-402c-b405-52efd878f80f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Początek EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81411c0a-4e7e-410b-b0f6-730101023dba",
   "metadata": {},
   "source": [
    "Analiza danych po ekstrakcji cech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f77a76d-ab97-404a-b4d1-8e32c59e7e8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "pd.options.display.max_columns = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0c2e00-1a06-43e3-a81b-747d2b65b443",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split_path = './data/features/'\n",
    "\n",
    "train_file_name = 'Amazon_train.json'\n",
    "test_file_name = 'Amazon_test.json'\n",
    "\n",
    "df_train = pd.read_json(os.path.join(split_path, train_file_name))\n",
    "df_test = pd.read_json(os.path.join(split_path, test_file_name))\n",
    "\n",
    "df = pd.concat([df_train, df_test], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f0258a-2583-456d-adfe-fa67a6311ffe",
   "metadata": {},
   "source": [
    "# Ogólna analiza danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3170516-4a2c-4c7f-80be-d0bf61803c37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb4d8fc-6ab7-449c-ba98-8926bfca50c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(df.isna().sum(axis=0).to_frame().transpose() / df.shape[0] * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65362b97-f47b-4ec2-b2a8-da6b88736e9d",
   "metadata": {},
   "source": [
    "* Czy i ile w zbiorze jest brakujących wartości? Dla jakich zmiennych? Co z tego wynika?\n",
    "\n",
    "W polach 'summary' i 'reviewText', zawierające tekst i które mają największe znaczenie w analizie wydźwięku, brakujących wartości jest mniej 1%, co jest dobre, bo prawie całe dane są przygodne do analizy.\n",
    "\n",
    "Nie mamy brakujących wartości w etykietach klas, co też jest dobre.\n",
    "\n",
    "Dużo brakujących wartości mamy w 'style_list' (oryginalnie Style) i odpowiednio w atrybutach, które powstały w procesie atomizacji: 'package quantity', 'design', 'format', 'scent name', 'flavor', 'style', 'package type', 'style name', 'color, size', 'size name', 'platform'. Nie są do użycia w trenowaniu modelu.\n",
    "\n",
    "Mamy dużo brakujących wartości w vote, to jest liczba odznaczeń od innych użytkowników, że ten review jest użyteczny. Nie obchodzi nas w analizie wydźwięku \n",
    "\n",
    "Image ma dużo brakujących wartości, ale ona zawiera link do obrazu, nie obchodzi nas w analizie wydźwięku\n",
    "\n",
    "'reviewerID' to ID użytkownika, nie ma brakujących wartości\n",
    "\n",
    "'asin' to ID produktu na Amazon, nie ma brakujących wartości\n",
    "\n",
    "'category' jest to kategoria produktu, nie ma brakujących wartości\n",
    "\n",
    "'reviewTime' i 'unixReviewTime' to czas (data w godzinie 00:00) w którym review został wysłany, nie ma brakujących wartości\n",
    "\n",
    "'summary_length', 'year_period' i 'time_period' to atrybuty oparte na atrybutach 'summary' i 'unixReviewTime' (i odpowiednio reviewTime)\n",
    "\n",
    "'year_period' i 'time_period' to wartości kategoryczne\n",
    "\n",
    "* Czy zbiór danych wydaje się być wystarczająco informacyjny by rozwiązać zadanie analizy sentymentu?\n",
    "\n",
    "W najważniejszych atrybutach dla analizy sentymentu, 'overall', 'summary' i 'reviewText', mamy bardzo mało brakujących wartości, dlatego prawie cały dataset jest przydatny do analizy. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891c3c29-9423-4124-bd54-4244ea7ec503",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Analiza danych numerycznych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c11478-8472-4ce7-86eb-7582df66c078",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38aef28b-ec74-4268-9771-173e672773b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "* Ile znajduje się w zbiorze cech kategorycznych, a ile numerycznych\n",
    "\n",
    "W zbiorze mamy 5 wartości numerycznych\n",
    "\n",
    "* Czy zmienna wyjściowa jest kategoryczna, czy numeryczna? \n",
    "\n",
    "Etykieta klasy jest wartością numeryczną, co znaczy że output modelu jest też numeryczny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fad253-498c-43cc-81f9-9581c747f13e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_corr = df[['overall', 'unixReviewTime', 'summary_length', 'reviewText_length', 'category', 'year_period']]\n",
    "\n",
    "# 'package quantity' usunięte bo maje tylko jedną wartość\n",
    "\n",
    "df_corr['category'] = df_corr['category'].apply(lambda x: 1 if x == 'Software_5' \n",
    "                                                else 2 if x =='All_Beauty_5' \n",
    "                                                else 3 if x =='AMAZON_FASHION_5'\n",
    "                                                else 4)\n",
    "\n",
    "df_corr['year_period'] = df_corr['year_period'].apply(lambda x: 1 if x =='winter' \n",
    "                                                else 2 if x =='spring' \n",
    "                                                else 3 if x =='autumn'\n",
    "                                                else 4)\n",
    "\n",
    "df_corr.corr()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "00f6f896-0f23-41b3-b343-53e8c5612f93",
   "metadata": {},
   "source": [
    "* Czy któreś z cech są skorelowane? Co z tego może wynikać?\n",
    "\n",
    "Mamy jakoś korelacje pomiędzy 'unixReviewTime' i 'category', to może wskazać na sezonowe trendy\n",
    "\n",
    "Mamy małą korelacje pomiędzy 'summary_length' i 'reviewText_length', długie teksty mają długie uogólnienia\n",
    "\n",
    "Mamy mała korelacje pomiędzy 'category' i 'overall', możemy zrobić hipotezę że jakieś kategorie produktów ogólnie otrzymują \n",
    "\n",
    "Ogólnie nie mamy silnych korelacji\n",
    "\n",
    "* Czy któraś z cech koreluje ze zmienną wyjściową? Jeśli tak - która? Czy któraś nie koreluje?\n",
    "\n",
    "'overall' ma relatywnie wysoką korelacje dla czasu i kategorii, ale nie ma dostatecznie silnych korelacji"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0864610-c15d-4f21-a1e8-8bed8110129f",
   "metadata": {},
   "source": [
    "# Analiza danych tekstowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7de1a1-a901-418e-b4f9-3188e3ed10a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_words_inReview = [y.lower() for x in df['reviewText'].to_list() if x != None for y in re.split('\\s|!|,|\\.|\\?', x)  if len(y) > 0]\n",
    "all_words_inSummary = [y.lower() for x in df['summary'].to_list() if x != None for y in re.split('\\s|!|,|\\.|\\?', x)  if len(y) > 0]\n",
    "\n",
    "words_counter_Rev = collections.Counter(all_words_inReview)\n",
    "words_counter_Sum = collections.Counter(all_words_inSummary)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "205b22f8-a59b-45d4-8b95-4b544428f896",
   "metadata": {},
   "source": [
    "Top N najwięcej występujących słów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03275bc-5137-47eb-85f1-2fa1db6efd4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = 15\n",
    "\n",
    "print('\\nSłowy w reviewText')\n",
    "for x in sorted(list(words_counter_Rev.items()), key = lambda x: x[1], reverse = True)[:N]:\n",
    "    print('\\t',x)\n",
    "\n",
    "print('\\nSłowy w summary')\n",
    "for x in sorted(list(words_counter_Sum.items()), key = lambda x: x[1], reverse = True)[:N]:\n",
    "    print('\\t',x)\n",
    "\n",
    "print('\\nOverall')\n",
    "for x in sorted(list((words_counter_Rev + words_counter_Sum).items()), key = lambda x: x[1], reverse = True)[:N]:\n",
    "    print('\\t',x)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3b8dd0c-4b0b-46c1-80cc-387a2b529e55",
   "metadata": {},
   "source": [
    "* Czy któreś ze słów wydają się dominować w zbiorze?\n",
    "\n",
    "W reviewText najwięcej występują słowy 'wspomagające' i nie niosą dużo informacji. Taka sama tendencja jest i w Summary.\n",
    "\n",
    "Ciekawą informacje mamy w 'summary', najwięcej mamy słów pozytywne \"five\" \"stars\" \"good\". Aby zrobić z tego wniosek musimy sprawdzić występowanie klas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d0e6d5-2e6f-483f-bdf8-572f3c0c0c09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['overall'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d506ed7-dc93-441f-b795-0f9a83d8cea4",
   "metadata": {
    "tags": []
   },
   "source": [
    "To potwierdza nasze obserwacje w 'summary', najwięcej mamy pozytywnych ocen, ocen w 5 gwiazd jest więcej niż wszystkich pozostałych ocen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfc32ff-eab6-4604-a7ac-1464a0bcc0b5",
   "metadata": {},
   "source": [
    "$$---$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ffa46d-add0-4aa4-a360-d32ac0babe23",
   "metadata": {
    "tags": []
   },
   "source": [
    "Teraz użyjemy NLTK aby usunąć 'common language'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402be34b-9c91-49fc-a277-819121d0ed7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_words_inReview = [y.lower() for x in df['reviewText'].to_list() if x != None for y in re.split('\\s|!|,|\\.|\\?', x)  if (len(y) > 0)]\n",
    "all_words_inSummary = [y.lower() for x in df['summary'].to_list() if x != None for y in re.split('\\s|!|,|\\.|\\?', x)  if (len(y) > 0)]\n",
    "\n",
    "words_counter_Rev = collections.Counter((x,y) for x,y in collections.Counter(all_words_inReview).items() if not x in stopwords.words())\n",
    "words_counter_Sum = collections.Counter((x,y) for x,y in collections.Counter(all_words_inSummary).items() if not x in stopwords.words())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df74b0e-4e5d-43ec-9bb5-e49ac2c1db38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = 15\n",
    "\n",
    "print('\\nSłowy w reviewText')\n",
    "for x in sorted(list(words_counter_Rev.items()), key = lambda x: x[1], reverse = True)[:N]:\n",
    "    print('\\t',x)\n",
    "\n",
    "print('\\nSłowy w summary')\n",
    "for x in sorted(list(words_counter_Sum.items()), key = lambda x: x[1], reverse = True)[:N]:\n",
    "    print('\\t',x)\n",
    "\n",
    "print('\\nOverall')\n",
    "for x in sorted(list((words_counter_Rev + words_counter_Sum).items()), key = lambda x: x[1], reverse = True)[:N]:\n",
    "    print('\\t',x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e820ec-479b-462f-84fc-34bb2364381b",
   "metadata": {},
   "source": [
    "Widać że w 'reviewText' najwięcej słów opisujących produkt i w wybranych słowach tylko \"great\" jest słowem opisującym emocje.\n",
    "\n",
    "To samo mniej więcej widać w 'summary', ale mamy więcej słów oceniających"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea51de1-9d80-49a2-a613-d8e7e0c651ee",
   "metadata": {},
   "source": [
    "* Jaka jest charakterystyka tekstu (np. długość, czystość)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4f0919-9d45-4f61-b54a-6b1ba05498a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.yscale(\"log\")\n",
    "plt.xlabel('reviewText_length')\n",
    "plt.hist(df['reviewText_length'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b62b147-cff7-43a2-985a-15e2a0a9a7d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.yscale(\"log\")\n",
    "plt.xlabel('summary_length')\n",
    "plt.hist(df['summary_length'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbc366e-d0a7-46ce-bf5b-a8e48de20709",
   "metadata": {},
   "source": [
    "# Analiza tekstu class-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf89775-8c30-4f86-a845-19a924d3b9f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classNum = 5\n",
    "N = 15\n",
    "\n",
    "all_words_inReview = [y.lower() for x in df[df['overall'] == classNum]['reviewText'].to_list() if x != None for y in re.split('\\s|!|,|\\.|\\?', x)  if len(y) > 0]\n",
    "all_words_inSummary = [y.lower() for x in df[df['overall'] == classNum]['summary'].to_list() if x != None for y in re.split('\\s|!|,|\\.|\\?', x)  if len(y) > 0]\n",
    "\n",
    "words_counter_Rev = collections.Counter(all_words_inReview)\n",
    "words_counter_Sum = collections.Counter(all_words_inSummary)\n",
    "\n",
    "print('\\nSłowy w reviewText')\n",
    "for x in sorted(list(words_counter_Rev.items()), key = lambda x: x[1], reverse = True)[:N]:\n",
    "    print('\\t',x)\n",
    "\n",
    "print('\\nSłowy w summary')\n",
    "for x in sorted(list(words_counter_Sum.items()), key = lambda x: x[1], reverse = True)[:N]:\n",
    "    print('\\t',x)\n",
    "\n",
    "print('\\nOverall')\n",
    "for x in sorted(list((words_counter_Rev + words_counter_Sum).items()), key = lambda x: x[1], reverse = True)[:N]:\n",
    "    print('\\t',x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "acb021f9-a6c2-4d91-abf5-657fd6f08916",
   "metadata": {},
   "source": [
    "* Czy najpopularniejsze słowa różnią się znacząco pomiędzy klasami? Czy potrafisz wyróżnić słowa mogące wpływać w znacznym stopniu na sentyment?\n",
    "\n",
    "Po analizie co klasy możemy wyróżnić następne słowy (dla wszystkich kategorii słów):\n",
    "\n",
    "1: not, buy, don't\n",
    "\n",
    "2: not\n",
    "\n",
    "3: not, but, good, needs\n",
    "\n",
    "4: good, great, works, but, four, just\n",
    "\n",
    "5: five, great, excellent, love,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b9ec56-bb86-45fa-a6ee-534a50228c9e",
   "metadata": {},
   "source": [
    "$$---$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8aaeb38f-67c0-46c7-9f7b-00cc2839caf2",
   "metadata": {},
   "source": [
    "Analiza z NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf8a13b-05bb-4b7d-a3d3-7b1c80c227e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classNum = 1\n",
    "N = 15\n",
    "\n",
    "all_words_inReview = [y.lower() for x in df[df['overall'] == classNum]['reviewText'].to_list() if x != None for y in re.split('\\s|!|,|\\.|\\?', x)  if len(y) > 0]\n",
    "all_words_inSummary = [y.lower() for x in df[df['overall'] == classNum]['summary'].to_list() if x != None for y in re.split('\\s|!|,|\\.|\\?', x)  if len(y) > 0]\n",
    "\n",
    "words_counter_Rev = collections.Counter(dict((x,y) for x,y in collections.Counter(all_words_inReview).items() if not x in stopwords.words()))\n",
    "words_counter_Sum = collections.Counter(dict((x,y) for x,y in collections.Counter(all_words_inSummary).items() if not x in stopwords.words()))\n",
    "\n",
    "print('\\nSłowy w reviewText')\n",
    "for x in sorted(list(words_counter_Rev.items()), key = lambda x: x[1], reverse = True)[:N]:\n",
    "    print('\\t',x)\n",
    "\n",
    "print('\\nSłowy w summary')\n",
    "for x in sorted(list(words_counter_Sum.items()), key = lambda x: x[1], reverse = True)[:N]:\n",
    "    print('\\t',x)\n",
    "\n",
    "print('\\nOverall')\n",
    "for x in sorted(list((words_counter_Rev + words_counter_Sum).items()), key = lambda x: x[1], reverse = True)[:N]:\n",
    "    print('\\t',x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeb21a4-04fe-4b6b-8e16-2fc567492f2c",
   "metadata": {},
   "source": [
    "Po analizie co klasy możemy wyróżnić następne słowy (dla wszystkich kategorii słów):\n",
    "\n",
    "1: failures, trouble, incompatibilities, waste, money, worthless, painfully\n",
    "\n",
    "2: buggy, free, problem, poor, slow\n",
    "\n",
    "3: easy, great, works, decent\n",
    "\n",
    "4: easy, great, excellent, nice, works\n",
    "\n",
    "5: great, love, easy, clean, easy, excellent, woked, works"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
